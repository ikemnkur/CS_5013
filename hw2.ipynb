{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "qc2aBWFz-V5a",
      "metadata": {
        "id": "qc2aBWFz-V5a"
      },
      "source": [
        "# Attempt to forecast the price of MSFT by analyzing the prices of multiple stocks, including MSFT, over several consecutive days leading up to the target day.\n",
        "#### N.B. Different setup from HW1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4342abc3",
      "metadata": {
        "id": "4342abc3"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader,Dataset\n",
        "\n",
        "class StockDataset(Dataset):\n",
        "    def __init__(self,X,Y,days):\n",
        "        self.X = X\n",
        "        self.Y = Y.reshape(-1)\n",
        "        self.days = days # days ahead for prediction\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.Y)-self.days)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        x=self.X[:,index:index+self.days]\n",
        "        y=self.Y[index+self.days]\n",
        "        return x,y\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f521af7d-ae88-4742-b390-31ecefbe39fe",
      "metadata": {
        "id": "f521af7d-ae88-4742-b390-31ecefbe39fe"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas\n",
        "# !pip install yfinance\n",
        "import numpy as np\n",
        "from numpy import exp, sum, log, log10\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "def get_price(tick,start='2020-01-01',end=None):\n",
        "    return yf.Ticker(tick).history(start=start,end=end)['Close']\n",
        "\n",
        "def get_prices(tickers,start='2020-01-01',end=None):\n",
        "    df=pd.DataFrame()\n",
        "    for s in tickers:\n",
        "        df[s]=get_price(s,start,end)\n",
        "    return df\n",
        "\n",
        "feature_stocks=['tsla','meta','nvda','amzn','nflx','gbtc','gdx','intc','dal','c','goog','aapl','msft','ibm','hp','orcl','sap','crm','hubs','twlo']\n",
        "predict_stock='msft'\n",
        "\n",
        "# getting data\n",
        "start_date='2020-01-01'\n",
        "\n",
        "allX=get_prices(feature_stocks,start=start_date)\n",
        "ally=get_prices([predict_stock],start=start_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "312706b5-74fb-48cf-946d-7d342cc25c6b",
      "metadata": {
        "id": "312706b5-74fb-48cf-946d-7d342cc25c6b"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data as data\n",
        "import torch\n",
        "\n",
        "stockData = StockDataset(allX.to_numpy().transpose().astype(np.float32),ally.to_numpy().astype(np.float32),days=5)\n",
        "train_set_size = int(len(stockData)*0.7)\n",
        "valid_set_size = int(len(stockData)*0.2)\n",
        "test_set_size = len(stockData)-train_set_size-valid_set_size\n",
        "\n",
        "train_set, valid_set, test_set = data.random_split(stockData,[train_set_size,valid_set_size,test_set_size],\\\n",
        "                                              generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "batch_size = train_set_size # use entire dataset as batch\n",
        "train_dataloader = DataLoader(train_set,batch_size=batch_size,shuffle=True)  # input:(20,5), label:1\n",
        "valid_dataloader = DataLoader(valid_set,batch_size=batch_size,shuffle=False)\n",
        "test_dataloader = DataLoader(test_set,batch_size=batch_size,shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oML-tGn7BCde",
      "metadata": {
        "id": "oML-tGn7BCde"
      },
      "source": [
        "# 1. Build a simple MLP to forecast MSFT price using PyTorch Lightning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "buk5w_lGCqo7",
      "metadata": {
        "id": "buk5w_lGCqo7"
      },
      "source": [
        "#### You have total freedom of your MLP. But your MLP should take the last five day ($5 \\times 20=100$) prices as input and you have to add dropout into your network."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "srXjIkTFBbWZ",
      "metadata": {
        "id": "srXjIkTFBbWZ"
      },
      "source": [
        "## 1a. Create a subclass of pytorch_lightning.LightningModule. It should include \\_\\_init\\_\\_, training_step, validation_step, configure_optimizers in the class. (6 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ftwjM2QaDD3a",
      "metadata": {
        "id": "ftwjM2QaDD3a"
      },
      "source": [
        "## 1b. Create a subclass of pytorch_lightning.LightningDataModule. It should include \\_\\_init\\_\\_, train_dataloader, and val_dataloader in the class. (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2vSgdTOoFI9e",
      "metadata": {
        "id": "2vSgdTOoFI9e"
      },
      "source": [
        "## 1c. Complete the rest of the code and train the model with 70% of the data. You should set aside 15% of the data each for validation and testing.  Show the training and validation MSE (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iI-CmJsPJ1K2",
      "metadata": {
        "id": "iI-CmJsPJ1K2"
      },
      "source": [
        "# 2. Construct a 1-D CNN to forecast MSFT stock price. You are free to use any design, but your network must consist of at least one convolutional layer and one dropout layer. You can also extend the duration leading up to the target day by modifying the \"days\" argument in the StockDataset. But \"days\" should not be larger than 32. (10 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZATXfRlsH7U2",
      "metadata": {
        "id": "ZATXfRlsH7U2"
      },
      "source": [
        "# 3. Please try to enhance the performance of the previously created MLP or CNN by applying hyperparameter tuning. You can use tools such as W&B hyperparameter sweep, SMAP, Optuna, or similar packages to achieve this. You need to optimize at least two parameters, with the dropout rate being one of them. (5 points)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/PyTorchLightning/pytorch-lightning"
      ],
      "metadata": {
        "id": "AuqKYB3NPNFw",
        "outputId": "1553833e-08e2-41d7-8baa-089f984a995f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AuqKYB3NPNFw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/PyTorchLightning/pytorch-lightning\n",
            "  Cloning https://github.com/PyTorchLightning/pytorch-lightning to /tmp/pip-req-build-m3_bj8m0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/PyTorchLightning/pytorch-lightning /tmp/pip-req-build-m3_bj8m0\n",
            "  Resolved https://github.com/PyTorchLightning/pytorch-lightning to commit ca13f77eab5d8b85ee84eb9fd7484c324ba198b1\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning==2.5.1rc2) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1rc2) (2025.3.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning==2.5.1rc2)\n",
            "  Downloading lightning_utilities-0.14.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.5.1rc2) (24.2)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.5.1rc2) (2.6.0+cu124)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning==2.5.1rc2)\n",
            "  Downloading torchmetrics-1.7.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.5.1rc2) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.5.1rc2) (4.12.2)\n",
            "Collecting pytorch-lightning (from lightning==2.5.1rc2)\n",
            "  Downloading pytorch_lightning-2.5.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1rc2) (3.11.14)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning==2.5.1rc2) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.5.1rc2) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.5.1rc2) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.5.1rc2) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning==2.5.1rc2)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning==2.5.1rc2)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning==2.5.1rc2)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<4.0,>=2.1.0->lightning==2.5.1rc2)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<4.0,>=2.1.0->lightning==2.5.1rc2)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<4.0,>=2.1.0->lightning==2.5.1rc2)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<4.0,>=2.1.0->lightning==2.5.1rc2)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<4.0,>=2.1.0->lightning==2.5.1rc2)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<4.0,>=2.1.0->lightning==2.5.1rc2)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.5.1rc2) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.5.1rc2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.5.1rc2) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning==2.5.1rc2)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.5.1rc2) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.5.1rc2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning==2.5.1rc2) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning==2.5.1rc2) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1rc2) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1rc2) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1rc2) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1rc2) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1rc2) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1rc2) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1rc2) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning==2.5.1rc2) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.5.1rc2) (3.10)\n",
            "Downloading lightning_utilities-0.14.2-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/664.8 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:01:25\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1443b1c5-da7a-4ad2-9a2f-889739406966",
      "metadata": {
        "id": "1443b1c5-da7a-4ad2-9a2f-889739406966"
      },
      "outputs": [],
      "source": [
        "# import pytorch_lightning as pl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ------------------------------\n",
        "# Dataset and Data Preparation\n",
        "# ------------------------------\n",
        "class StockDataset(Dataset):\n",
        "    def __init__(self, X, Y, days):\n",
        "        self.X = X\n",
        "        self.Y = Y.reshape(-1)\n",
        "        self.days = days  # days ahead for prediction\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Y) - self.days\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.X[:, index:index + self.days]  # shape: (num_stocks, days)\n",
        "        y = self.Y[index + self.days]\n",
        "        return x, y\n",
        "\n",
        "def get_price(tick, start='2020-01-01', end=None):\n",
        "    return yf.Ticker(tick).history(start=start, end=end)['Close']\n",
        "\n",
        "def get_prices(tickers, start='2020-01-01', end=None):\n",
        "    df = pd.DataFrame()\n",
        "    for s in tickers:\n",
        "        df[s] = get_price(s, start, end)\n",
        "    return df\n",
        "\n",
        "# Define tickers\n",
        "feature_stocks = ['tsla','meta','nvda','amzn','nflx','gbtc','gdx','intc','dal','c','goog','aapl','msft','ibm','hp','orcl','sap','crm','hubs','twlo']\n",
        "predict_stock = 'msft'\n",
        "start_date = '2020-01-01'\n",
        "\n",
        "allX = get_prices(feature_stocks, start=start_date)\n",
        "ally = get_prices([predict_stock], start=start_date)\n",
        "\n",
        "# Create dataset: note that we transpose allX so that each column is a time step.\n",
        "stockData = StockDataset(allX.to_numpy().transpose().astype(np.float32),\n",
        "                         ally.to_numpy().astype(np.float32),\n",
        "                         days=5)\n",
        "\n",
        "# Split dataset: 70% train, 15% valid, 15% test.\n",
        "dataset_size = len(stockData)\n",
        "train_size = int(dataset_size * 0.70)\n",
        "valid_size = int(dataset_size * 0.15)\n",
        "test_size = dataset_size - train_size - valid_size\n",
        "\n",
        "train_set, valid_set, test_set = random_split(stockData, [train_size, valid_size, test_size],\n",
        "                                                generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "batch_size = 64  # you can adjust the batch size as needed\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------\n",
        "# Lightning Data Module\n",
        "# ------------------------------\n",
        "class StockDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, train_set, valid_set, test_set, batch_size):\n",
        "        super().__init__()\n",
        "        self.train_set = train_set\n",
        "        self.valid_set = valid_set\n",
        "        self.test_set = test_set\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.valid_set, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_set, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "data_module = StockDataModule(train_set, valid_set, test_set, batch_size)\n",
        "\n",
        "# ------------------------------\n",
        "# Lightning Module: MLP Forecasting Model\n",
        "# ------------------------------\n",
        "class MSFTForecastingMLP(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super(MSFTForecastingMLP, self).__init__()\n",
        "        # The input is 5 days of data for 20 stocks: 5*20 = 100 features.\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Flatten(),              # Flatten input (20, 5) -> (100,)\n",
        "            nn.Linear(100, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(32, 1)           # Output single forecast value\n",
        "        )\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self.criterion(y_hat, y)\n",
        "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = self.criterion(y_hat, y)\n",
        "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
        "        return optimizer\n",
        "\n",
        "# ------------------------------\n",
        "# Callback to Record Loss History\n",
        "# ------------------------------\n",
        "class LossHistory(pl.Callback):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "\n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        # trainer.callback_metrics is a dictionary that stores the logged metrics.\n",
        "        # Ensure the keys match those we logged.\n",
        "        train_loss = trainer.callback_metrics.get(\"train_loss\")\n",
        "        val_loss = trainer.callback_metrics.get(\"val_loss\")\n",
        "        if train_loss is not None and val_loss is not None:\n",
        "            self.train_losses.append(train_loss.item())\n",
        "            self.val_losses.append(val_loss.item())\n"
      ],
      "metadata": {
        "id": "gYB63YVpJtpR"
      },
      "id": "gYB63YVpJtpR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Instantiate model and callback\n",
        "model = MSFTForecastingMLP()\n",
        "loss_history = LossHistory()\n",
        "\n",
        "# ------------------------------\n",
        "# Training\n",
        "# ------------------------------\n",
        "# Set up PyTorch Lightning Trainer\n",
        "trainer = pl.Trainer(max_epochs=25, callbacks=[loss_history], log_every_n_steps=1, progress_bar_refresh_rate=20)\n",
        "\n",
        "# Train the model using the data module (which provides 70% training and 15% validation data)\n",
        "trainer.fit(model, datamodule=data_module)\n",
        "\n",
        "# ------------------------------\n",
        "# Plotting Training and Validation MSE vs Epoch\n",
        "# ------------------------------\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(loss_history.train_losses, label='Training MSE')\n",
        "plt.plot(loss_history.val_losses, label='Validation MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.title('Training and Validation MSE vs. Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ym-KRnu7J06U"
      },
      "id": "Ym-KRnu7J06U",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "buk5w_lGCqo7",
        "srXjIkTFBbWZ",
        "2vSgdTOoFI9e",
        "iI-CmJsPJ1K2",
        "ZATXfRlsH7U2"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}